{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset (first 5 rows):\n",
      "   animal_name  hair  feathers  eggs  milk  airborne  aquatic  predator  \\\n",
      "0    aardvark     1         0     0     1         0        0         1   \n",
      "1    antelope     1         0     0     1         0        0         0   \n",
      "2        bass     0         0     1     0         0        1         1   \n",
      "3        bear     1         0     0     1         0        0         1   \n",
      "4        boar     1         0     0     1         0        0         1   \n",
      "\n",
      "   toothed  backbone  breathes  venomous  fins  legs  tail  domestic  catsize  \\\n",
      "0        1         1         1         0     0     4     0         0        1   \n",
      "1        1         1         1         0     0     4     1         0        1   \n",
      "2        1         1         0         0     1     0     1         0        0   \n",
      "3        1         1         1         0     0     4     0         0        1   \n",
      "4        1         1         1         0     0     4     1         0        1   \n",
      "\n",
      "   class_type  \n",
      "0           1  \n",
      "1           1  \n",
      "2           4  \n",
      "3           1  \n",
      "4           1  \n",
      "\n",
      "Label Encoding for Target Variable (class_type):\n",
      " [1, 2, 3, 4, 5, 6, 7]\n",
      "\n",
      "Dataset after 'legs' Normalization (first 5 rows):\n",
      "    hair  feathers  eggs  milk  airborne  aquatic  predator  toothed  backbone  \\\n",
      "0     1         0     0     1         0        0         1        1         1   \n",
      "1     1         0     0     1         0        0         0        1         1   \n",
      "2     0         0     1     0         0        1         1        1         1   \n",
      "3     1         0     0     1         0        0         1        1         1   \n",
      "4     1         0     0     1         0        0         1        1         1   \n",
      "\n",
      "   breathes  venomous  fins  legs  tail  domestic  catsize  \n",
      "0         1         0     0   0.5     0         0        1  \n",
      "1         1         0     0   0.5     1         0        1  \n",
      "2         0         0     1   0.0     1         0        0  \n",
      "3         1         0     0   0.5     0         0        1  \n",
      "4         1         0     0   0.5     1         0        1  \n",
      "\n",
      "Shapes of Training and Testing Sets:\n",
      "X_train: (80, 16)\n",
      "X_test: (21, 16)\n",
      "y_train: (80,)\n",
      "y_test: (21,)\n",
      "\n",
      "First 5 Samples of Training Data (as Tensors):\n",
      " tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.5000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 0.0000, 0.5000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.7500, 0.0000, 0.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.5000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.7500, 0.0000, 0.0000, 0.0000]])\n",
      "\n",
      "First 5 Labels of Training Data (as Tensors):\n",
      " tensor([4, 4, 5, 0, 6])\n",
      "\n",
      "A single batch of features (training):\n",
      " tensor([[0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.2500, 1.0000, 0.0000, 1.0000],\n",
      "        [1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.5000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.5000, 1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.7500, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.5000, 0.0000, 0.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.5000, 1.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000],\n",
      "        [1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.5000, 1.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.2500, 1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.7500, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.2500, 1.0000, 1.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.5000, 1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.5000, 1.0000, 0.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.5000, 1.0000, 0.0000, 1.0000],\n",
      "        [1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.7500, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.2500, 1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.5000, 1.0000, 0.0000, 1.0000],\n",
      "        [1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.5000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.7500, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.6250, 0.0000, 0.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.2500, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.2500, 1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.2500, 1.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 0.0000, 0.5000, 0.0000, 0.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000],\n",
      "        [1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.5000, 0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.2500, 1.0000, 0.0000, 0.0000]])\n",
      "\n",
      "A single batch of labels (training):\n",
      " tensor([1, 0, 2, 5, 2, 6, 0, 3, 0, 1, 5, 1, 0, 3, 0, 0, 5, 3, 0, 6, 0, 0, 6, 6,\n",
      "        0, 1, 1, 4, 0, 3, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Load the dataset (assuming zoo.data is in the working directory)\n",
    "\n",
    "# Column names based on zoo.names\n",
    "column_names = ['animal_name', 'hair', 'feathers', 'eggs', 'milk', 'airborne', \n",
    "                'aquatic', 'predator', 'toothed', 'backbone', 'breathes', \n",
    "                'venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']\n",
    "\n",
    "# Load the dataset into a pandas dataframe\n",
    "df = pd.read_csv((r'C:\\Users\\haris\\OneDrive\\Documents\\zoo.data.csv'), header=None, names=column_names)\n",
    "\n",
    "# Print the first few rows of the original dataset\n",
    "print(\"Original Dataset (first 5 rows):\\n\", df.head())\n",
    "\n",
    "# Drop the animal_name column as it's not a feature used in training\n",
    "df = df.drop('animal_name', axis=1)\n",
    "\n",
    "# Separate the features and the target variable\n",
    "X = df.drop('class_type', axis=1)  # Features\n",
    "y = df['class_type']  # Target\n",
    "\n",
    "# Step 1: Label Encoding for the Target Variable (class_type)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Print the label encoding mapping\n",
    "print(\"\\nLabel Encoding for Target Variable (class_type):\\n\", list(label_encoder.classes_))\n",
    "\n",
    "# Step 2: Normalization of the 'legs' attribute\n",
    "scaler = MinMaxScaler()\n",
    "X['legs'] = scaler.fit_transform(X[['legs']])\n",
    "\n",
    "# Print the first few rows after normalization\n",
    "print(\"\\nDataset after 'legs' Normalization (first 5 rows):\\n\", X.head())\n",
    "\n",
    "# Step 3: No One-Hot Encoding is needed for Boolean features (already binary)\n",
    "\n",
    "# Step 4: Train-Test Split (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the training and testing sets\n",
    "print(\"\\nShapes of Training and Testing Sets:\")=\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"y_test:\", y_test.shape)\n",
    "\n",
    "# Step 5: Handle class imbalance (optional, depending on the class distribution)\n",
    "# Not handling class imbalance in this case since the dataset is reasonably balanced\n",
    "\n",
    "# Step 6: Convert the preprocessed data into Tensor format\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Print the first few tensors\n",
    "print(\"\\nFirst 5 Samples of Training Data (as Tensors):\\n\", X_train_tensor[:5])\n",
    "print(\"\\nFirst 5 Labels of Training Data (as Tensors):\\n\", y_train_tensor[:5])\n",
    "\n",
    "# Step 7: Batching and Shuffling\n",
    "batch_size = 32\n",
    "\n",
    "# Create DataLoader for training and testing datasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Print out a single batch of data from the train_loader\n",
    "for batch_features, batch_labels in train_loader:\n",
    "    print(\"\\nA single batch of features (training):\\n\", batch_features)\n",
    "    print(\"\\nA single batch of labels (training):\\n\", batch_labels)\n",
    "    break  # Only print the first batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports:\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "pandas: A library for data manipulation and analysis. Here, it's used to load and manage the dataset.\n",
    "\n",
    "\n",
    "train_test_split: A function from sklearn to split the dataset into training and testing sets.\n",
    "\n",
    "LabelEncoder: Used to convert categorical labels into a numerical format.\n",
    "\n",
    "MinMaxScaler: Used to normalize numerical data (i.e., scale the data between a range, usually 0 to 1).\n",
    "\n",
    "torch: The core library of PyTorch, a deep learning framework.\n",
    "\n",
    "DataLoader and TensorDataset: Used to create iterable datasets for training in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Dataset:\n",
    "\n",
    "# Column names based on zoo.names\n",
    "\n",
    "column_names = ['animal_name', 'hair', 'feathers', 'eggs', 'milk', 'airborne', \n",
    "\n",
    "                'aquatic', 'predator', 'toothed', 'backbone', 'breathes',\n",
    "\n",
    "                'venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']\n",
    "\n",
    "\n",
    "# Load the dataset into a pandas dataframe\n",
    "\n",
    "df = pd.read_csv((r'C:\\Users\\haris\\OneDrive\\Documents\\zoo.data.csv'), header=None, names=column_names)\n",
    "\n",
    "\n",
    "# Print the first few rows of the original dataset\n",
    "\n",
    "print(\"Original Dataset (first 5 rows):\\n\", df.head())\n",
    "\n",
    "column_names: Defines the column names for the dataset. Since the dataset doesn’t come with headers, column names are manually set based on the attributes of the \"zoo\" dataset.\n",
    "\n",
    "\n",
    "pd.read_csv(): Loads the dataset from the specified file path into a pandas DataFrame. The header=None argument indicates there is no header in the CSV file, so column names are provided.\n",
    "\n",
    "\n",
    "df.head(): Prints the first 5 rows of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping the Animal Name Column:\n",
    "\n",
    "df = df.drop('animal_name', axis=1)\n",
    "\n",
    "df.drop(): Drops the 'animal_name' column since it’s not useful for training the model. The axis=1 specifies that the column (and not a row) is being dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating Features and Target Variable:\n",
    "X = df.drop('class_type', axis=1)  \n",
    "\n",
    "y = df['class_type'] \n",
    "\n",
    "X: Contains all columns except 'class_type' (which is the target). These are the features used for model training.\n",
    "\n",
    "y: The 'class_type' column, which represents the classification target.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding the Target Variable:\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "# Print the label encoding mapping\n",
    "\n",
    "print(\"\\nLabel Encoding for Target Variable (class_type):\\n\", list(label_encoder.classes_))\n",
    "\n",
    "LabelEncoder(): Converts the target variable ('class_type') into numeric values. Each unique class type will be mapped to an integer \n",
    "\n",
    "fit_transform(y): Fits the encoder to the 'class_type' column and transforms it into a numerical array.\n",
    "\n",
    "list(label_encoder.classes_): Prints the unique classes and their corresponding numeric labels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing the 'Legs' Feature:\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X['legs'] = scaler.fit_transform(X[['legs']])\n",
    "\n",
    "\n",
    "\n",
    "# Print the first few rows after normalization\n",
    "\n",
    "print(\"\\nDataset after 'legs' Normalization (first 5 rows):\\n\", X.head())\n",
    "\n",
    "MinMaxScaler(): Scales the 'legs' feature so that the values are between 0 and 1. Normalization is often done to ensure that no feature dominates others due to larger values.\n",
    "\n",
    "fit_transform(X[['legs']]): Normalizes the 'legs' column.\n",
    "\n",
    "X.head(): Prints the first 5 rows after normalization to verify the transformation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Dataset into Training and Testing Sets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Print the shapes of the training and testing sets\n",
    "\n",
    "print(\"\\nShapes of Training and Testing Sets:\")\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "\n",
    "print(\"X_test:\", X_test.shape)\n",
    "\n",
    "print(\"y_train:\", y_train.shape)\n",
    "\n",
    "print(\"y_test:\", y_test.shape)\n",
    "\n",
    "train_test_split(): Splits the dataset into training (80%) and testing (20%) sets. The random_state=42 ensures reproducibility of the split.\n",
    "\n",
    "X_train, X_test, y_train, y_test: The resulting feature and target sets for training and testing.\n",
    "\n",
    ".shape: Prints the dimensions of the training and testing datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Data to Tensor Format (for PyTorch):\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Print the first few tensors\n",
    "\n",
    "print(\"\\nFirst 5 Samples of Training Data (as Tensors):\\n\", X_train_tensor[:5])\n",
    "\n",
    "print(\"\\nFirst 5 Labels of Training Data (as Tensors):\\n\", y_train_tensor[:5])\n",
    "\n",
    "torch.tensor(): Converts the training and testing data into PyTorch tensors, which are required for training models in PyTorch.\n",
    "\n",
    "X_train.values: Converts the pandas DataFrame into a NumPy array before creating a tensor.\n",
    "\n",
    "dtype=torch.float32 and dtype=torch.long: Specifies the data types for the features and labels, respectively.\n",
    "\n",
    "[:5]: Displays the first 5 rows of the tensor data for inspection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating DataLoader for Batching and Shuffling:\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create DataLoader for training and testing datasets\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "TensorDataset(): Combines the features and labels into a dataset that PyTorch can iterate through.\n",
    "\n",
    "DataLoader(): Creates an iterable data loader that batches the data.\n",
    "\n",
    "batch_size=32: Each batch contains 32 samples.\n",
    "\n",
    "shuffle=True for training data: Randomly shuffles the training data at each epoch to improve learning.\n",
    "\n",
    "shuffle=False for testing data: No need to shuffle testing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying a Single Batch of Data:\n",
    "for batch_features, batch_labels in train_loader:\n",
    "\n",
    "    print(\"\\nA single batch of features (training):\\n\", batch_features)\n",
    "\n",
    "    print(\"\\nA single batch of labels (training):\\n\", batch_labels)\n",
    "\n",
    "    break  \n",
    "\n",
    "    This loop extracts a single batch of data from the training loader.\n",
    "\n",
    "batch_features: A batch of features.\n",
    "\n",
    "batch_labels: Corresponding labels.\n",
    "\n",
    "The break ensures that only the first batch is printed.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of the Code:\n",
    "\n",
    "This code performs data preprocessing and prepares the Zoo dataset for use in a PyTorch deep learning model. Here's the flow of the script:\n",
    "\n",
    "# 1:Loading the Dataset:\n",
    "\n",
    "The dataset is loaded into a pandas DataFrame with specified column names. The 'animal_name' column is dropped as it's irrelevant for training.\n",
    "\n",
    "# 2:Separating Features and Target:\n",
    "\n",
    "The features (X) are separated from the target variable (y), which represents the class type (animal classification).\n",
    "\n",
    "# 3:Label Encoding the Target:\n",
    "\n",
    "The target variable (class_type) is converted into numerical labels using LabelEncoder, where each unique class is assigned a numerical value (e.g., 0, 1, 2).\n",
    "\n",
    "# 4:Normalizing a Feature:\n",
    "\n",
    "The 'legs' feature, which is a numerical value, is scaled to a range of 0 to 1 using MinMaxScaler to ensure consistent scaling during model training.\n",
    "\n",
    "# 5:Train-Test Split:\n",
    "\n",
    "The dataset is split into training (80%) and testing (20%) sets using train_test_split to prepare the data for training and evaluation.\n",
    "\n",
    "# 6:Converting to PyTorch Tensors:\n",
    "\n",
    "Both the features and labels from the training and testing sets are converted into PyTorch tensors to be used with deep learning models in PyTorch.\n",
    "\n",
    "# 7:Creating Data Loaders:\n",
    "\n",
    "\n",
    "DataLoader objects are created for both training and testing sets, which allows the data to be batched (with a batch size of 32) and shuffled for efficient model training. \n",
    "\n",
    "Batching improves the performance of the model, and shuffling enhances generalization during training.\n",
    "\n",
    "# 8:Displaying a Batch of Data:\n",
    "\n",
    "The script demonstrates how to extract and display a single batch of training data from the DataLoader, including both features and their corresponding labels.\n",
    "\n",
    "\n",
    "This preprocessing pipeline converts the Zoo dataset into a format that is ready for deep learning models, ensuring proper data scaling, encoding, batching, and efficient data loading using PyTorch."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
